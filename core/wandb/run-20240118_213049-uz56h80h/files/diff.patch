diff --git a/core/data_utils/load_cora.py b/core/data_utils/load_cora.py
index b151741..bf8e416 100644
--- a/core/data_utils/load_cora.py
+++ b/core/data_utils/load_cora.py
@@ -4,10 +4,10 @@ import random
 
 from torch_geometric.datasets import Planetoid
 import torch_geometric.transforms as T
-
+import os
 
 # return cora dataset as pytorch geometric Data object together with 60/20/20 split, and list of cora IDs
-
+root_path = '/pfs/work7/workspace/scratch/cc7738-nlp_graph/TAPE_chen/dataset'
 
 def get_cora_casestudy(SEED=0):
     data_X, data_Y, data_citeid, data_edges = parse_cora()
@@ -53,7 +53,7 @@ def get_cora_casestudy(SEED=0):
 
 
 def parse_cora():
-    path = 'dataset/cora_orig/cora'
+    path = root_path + '/cora_orig/cora'
     idx_features_labels = np.genfromtxt(
         "{}.content".format(path), dtype=np.dtype(str))
     data_X = idx_features_labels[:, 1:-1].astype(np.float32)
@@ -78,7 +78,7 @@ def get_raw_text_cora(use_text=False, seed=0):
     if not use_text:
         return data, None
 
-    with open('dataset/cora_orig/mccallum/cora/papers')as f:
+    with open(root_path + '/cora_orig/mccallum/cora/papers')as f:
         lines = f.readlines()
     pid_filename = {}
     for line in lines:
@@ -86,17 +86,33 @@ def get_raw_text_cora(use_text=False, seed=0):
         fn = line.split('\t')[1]
         pid_filename[pid] = fn
 
-    path = 'dataset/cora_orig/mccallum/cora/extractions/'
+    path = root_path + '/cora_orig/mccallum/cora/extractions/'
     text = []
+    not_loaded = []
+    i = 0
     for pid in data_citeid:
         fn = pid_filename[pid]
-        with open(path+fn) as f:
-            lines = f.read().splitlines()
-
-        for line in lines:
-            if 'Title:' in line:
-                ti = line
-            if 'Abstract:' in line:
-                ab = line
-        text.append(ti+'\n'+ab)
+        try:
+            if os.path.exists(path+fn): 
+                pathfn = path+fn
+            elif os.path.exists(path+fn.replace(":", "_")):
+                pathfn = path+fn.replace(":", "_")
+            elif os.path.exists(path+fn.replace("_", ":")):
+                pathfn = path+fn.replace("_", ":")
+                
+            with open(pathfn) as f:
+                lines = f.read().splitlines()
+                    
+            for line in lines:
+                if 'Title:' in line:
+                    ti = line
+                if 'Abstract:' in line:
+                    ab = line
+            text.append(ti+'\n'+ab)
+        except:
+            not_loaded.append(pathfn)
+            i += 1
+
+        # print(f"not loaded {i} papers.")
+        # print(f"not loaded papers: {not_loaded}")
     return data, text
diff --git a/core/trainLM.py b/core/trainLM.py
index e7caf13..ebc22c1 100644
--- a/core/trainLM.py
+++ b/core/trainLM.py
@@ -1,3 +1,5 @@
+import os, sys
+sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
 from core.LMs.lm_trainer import LMTrainer
 from core.config import cfg, update_cfg
 import pandas as pd
